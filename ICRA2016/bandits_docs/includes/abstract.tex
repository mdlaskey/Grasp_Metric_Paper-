\begin{abstract}
Advances in computing and massive datasets of images and human speech have produced recent results that surpass decades of past research on analytic methods..
This raises the question: can Big Data and Cloud Computation produce analogous advances in robot grasping and manipulation?
We develop an algorithm based on a Multi-Armed Bandit model with correlated rewards and show that our algorithm can leverage a large dataset of prior grasps and 3D object models to reduce the number of samples needed for robust grasp planning.
To study scaling effects, we introduce the Dexterity Network (Dex-Net) 1.0, a growing dataset that currently includes over 10,000 unique 3D object models and 2.5 million parallel-jaw grasps along with the probability of force closure of each grasp under uncertainty in object pose, gripper pose, and friction coefficient.
We use Multi-View Convolutional Neural Networks (MV-CNNs), a new deep learning method for 3D object classification, to learn a similarity metric between objects and apply MV-CNNs to indexing similar objects for grasp planning at scale.
We implement Dex-Net 1.0 using the Google Cloud Platform with a system that can simultaneously run up to 1,500 virtual machines, reducing experiment runtime by up to 1000$\times$.
Experiments suggest that robust grasp planning is up to 3.5$\times$ faster than Thompson sampling without prior data and that average grasp quality scales with the size of the dataset when the MV-CNN returns geometrically similar objects.
We also explore sensitivity of our algorithm to similarity metrics and pose and friction uncertainty levels for test objects.
Code, data, and additional information can be found at: \TODO{Url}
\end{abstract}