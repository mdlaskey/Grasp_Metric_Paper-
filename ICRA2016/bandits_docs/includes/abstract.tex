\begin{abstract}
%\TODO{Adapted from flyer, probably needs to be toned down}
Advances in Big Data and distributed computing, combined with very large datasets of images and human speech, have produced a series of  data-driven results that surpass decades of research in analytic methods and, in some cases, that surpass human ability.
For example, deep neural networks can now learn to play video games, recognize faces, and translate between languages.
This raises the question: can Big Data and computation produce analogous advances in robot grasping and manipulation?
We introduce the Dexterity-Network (Dex-Net) 1.0, a Cloud-based dataset of 3D object models labelled with parallel-jaw grasps and similarity between objects and grasps based on multi-view Convolutional Neural Networks (CNNs) and grasp heightmaps.
We use Dex-Net in Multi-Armed Bandit (MAB) algorithms to quickly find a grasp with high probability of force closure on an object from a set of 250 candidates. 
We extend previous MAB models to predict grasp quality using similiarity to prior objects and grasps in Dex-Net using Continuous Correlated Beta Processes (CCBPs).
Our initial results suggest that using prior objects from Dex-Net can accelerate grasp planning by up to $10\times$.
%\TODO{More concrete results here as I organize them} 
Code, data, and additional information can be found at: \TODO{Url}
\end{abstract}