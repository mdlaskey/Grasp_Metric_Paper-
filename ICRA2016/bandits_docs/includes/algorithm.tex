\section{Correlated Multi-Armed Bandit Algorithm}
\seclabel{algorithm}
The Dex-Net 1.0 algorithm (see pseudocode below) optimizes the probability of success $P_S$ (Equation~\ref{eq:obj}) for a binary quality metric $S$ such as force closure over a set of candidate grasps for an object $\mO$ using a Bayesian Multi-Armed Bandit (MAB) model~\cite{laskey2015bandits, srinivas10gaussian} with correlated rewards~\cite{hoffman2013exploiting, pandey2007multi} and priors computed from Dex-Net 1.0.
We first generate a set of $K$ candidate grasps, or ``arms", $\Gamma$ for object $\mO$ using the antipodal grasp sampling described in \secref{grasp-sampling}.
Next, we predict $P_S$ for each grasp using the $M$ most similar objects from the Dex-Net 1.0 dataset and estimate a Bayesian posterior distribution on our prediction.
Then, for iterations $t=1,...,T$ we use Thompson sampling~\cite{laskey2015bandits, oberlin2015autonomously} to select a grasp $\bg_{t,k} \in \Gamma$ to evaluate, sample the quality $S(\bg_{t,k})$, and update a posterior belief distribution on $P_S$ for each grasp.
Finally, we rank $\Gamma$ by the $q$-lower confidence bound on $P_S$ for each grasp and store the ranking in the database.
To illustrate convergence of the algorithm, we use force closure~\cite{zheng2005} as our binary quality metric.
We plan to study other quality metrics such as success on physical trials~\cite{kroemer2010combining, montesano2012active} and alternate MAB methods based on upper confidence bounds~\cite{kroemer2010combining, oberlin2015autonomously} or Gittins indices~\cite{laskey2015bandits} in future work.

\subsection{Model of Correlated Rewards}
\seclabel{belief}
Let $\mO$ denote the test object to label with the Dex-Net algorithm, and let $\Gamma$ be the set of $N_g$ candidate grasps generated for $\mO$.
Let $S_{j} = S(\bg_{j}) \in \{0, 1\}$ be a random binary quality metric evaluated on grasp $\bg_{j} \in \Gamma$.
For example, $S_j$ might model force closure under uncertainty in object pose, gripper pose, or friction. 
$S_j$ is a Bernoulli random variable with probability of success $\theta_{j}= P_S(\bg_{j})$.

We use Continuous Correlated Beta Processes (CCBPs)~\cite{goetschalckx2011continuous, montesano2012active} to model a joint posterior belief distribution over the $\theta_j$ for all grasps in Dex-Net, which enables us to predict $\theta_j$ from prior grasp and object data in Dex-Net 1.0 using a closed-form posterior update.
The joint distribution models pairwise correlations of $P_S$ between grasp-object pairs $\mP = (\bg, \mO)$ measured using a normalized kernel function $k(\mP_i, \mP_j)$.
%Such correlations may occur between grasps contacting an object at similar locations.
The kernel approaches 1 as the arguments become increasingly similar and approaches 0 as the arguments become dissimilar.

We measure similarity using a set of feature maps $\phi_m \in \mathbb{R}^{d_m}$ for $m = 1, ..., 3$, where $d_m$ is the dimension of the feature space for each.
The first feature map $\phi_{1}(\mP) = (\bx, \bv, \| \rho_1 \|_2, \| \rho_2 \|_2)$ captures similiarity in the grasp parameters, where $\bx \in \bR^3$ is the grasp center, $\bv \in \bS^2$ is the approach axis, and $\rho_i \in \bR^3$ is the $i$-th moment arm.
To capture local surface geometry, the second feature map $\phi_{2}(\mP) = \eta(\bg, \mO)$, the differential depthmap described in \secref{grasp-similarity}.
To capture global shape information, our third feature map $\phi_{3}(\mP) = \psi(\mO)$, where $\psi$ is our object similarity map described in \secref{object-similarity}.
Given the feature maps, we use the squared exponential kernel 
\begin{align*}
	k(\mY_p, \mY_q) &= \exp\left( - \frac{1}{2} \sum \limits_{m=1}^{3} \|\phi_m(\mP_p) - \phi_m(\mP_q)\|_{C_m}^2 \right).
\end{align*}
\noindent where $C_m \in \bR^{d_m \times d_m}$ is the bandwidth for $\phi_m$ and $\| \by \|_{C_m} = \by^T C_m^{-1} \by$.
The bandwidths are set by maximizing the log-likelihood~\cite{goetschalckx2011continuous} of the true $P_S$ under the CCBP on a set of training data.

%We maintain a posterior C belief distribution~\cite{hoffman2013exploiting, laskey2015bandits} on $\theta_{j}$ based on samples of $S_j$. 
% TODO: why introduce this, put CCBP model here

%The algorithm approximately optimizes Equation~\ref{eq:obj} following the Bayesian MAB model~\cite{oberlin2015autonomously, srinivas10gaussian} by selecting a grasp $\bg_{k,t}$ on iteration $t$ from our set of ``arms" $\Gamma$ using Thompson Sampling~\cite{laskey2015bandits}, observing $S(\bg_{k,t})$, and updating a Bayesian posterior on $P_S(\bg_{k,t})$.


%The Beta distribution $\betadist(\alpha, \beta) = Z(\alpha, \beta) \theta_j^{\alpha-1} (1 - \theta_j)^{\beta-1}$, where $\alpha > 0$ and $\beta > 0$ are shape parameters and $Z(\alpha, \beta)$ is a normalization constant.
%One benefit of $\betadist$ is the closed-form updates to $\alpha$ and $\beta$ upon observing a quality evaluation $S_{j,t}$:
%TODO: closed form updates

\subsection{Predicting Grasp Quality Using Prior Data}
\seclabel{ccbps}
Before evaluating any grasps in $\Gamma$, the Dex-Net 1.0 algorithm predicts $\theta_j$ for each candidate grasp $\bg_j$ based on its kernel similarity to all grasps and objects from the Dex-Net 1.0 dataset $\mD$.
In particular, we estimate a Bayesian posterior density $p(\theta_j)$ by treating $\mD$ as prior observations and using the closed form posterior update for CCBPs~\cite{goetschalckx2011continuous}:
%\vspace{-2ex}
\begin{align}
 	p(\theta_j \mid \alpha_{j,0}, \beta_{j,0} ) &\propto \theta_j^{\alpha_{j,0}-1} (1 - \theta_j)^{\beta_{j,0}-1} \\
	\alpha_{j,0} = \alpha_{0} & + \sum \limits_{i=1}^{| \mD |} \sum \limits_{k=1}^{K} k(\mP_{j}, \mP_{i, k}) Z_{i,k} \label{eq:alpha-prior} \\
	\beta_{j,0} = \beta_{0} & + \sum \limits_{i=1}^{| \mD |} \sum \limits_{k=1}^{K}  k(\mP_{j}, \mP_{i,k}) (N - Z_{i,k}) \label{eq:beta-prior}
\end{align}
\noindent where $\alpha_{0}$ and $\beta_{0}$ are prior parameters for the Beta distribution~\cite{laskey2015bandits}, $N$ is the number of times each grasp $\bg_{i,k} \in \mD$ was sampled to estimate $\theta_i$, and $Z_{i,k}$ is the number of observed successes for $\bg_{i,k}$. 
Intuitively, the prior dataset contributes fractional observations of successes and failures for the grasp candidates $\Gamma$ proportional to the kernel similarity.
We estimate the above sums using the $M$ nearest neighbors to $\mO$ in the object similarity KD-Tree described in \secref{object-similarity}. 

\subsection{Grasp Selection Policy}
On iteration $t$ we select the next grasp to sample $\bg_j \in \Gamma$ using Thompson Sampling.
In Thompson Sampling we draw a sample $\hat{\theta_{\ell}} \sim p(\theta_{\ell} \mid \alpha_{\ell,t}, \beta_{\ell,t} )$ for each grasp $\bg_{\ell} \in \Gamma$, then choose the grasp $\bg_j$ with the highest $\hat{\theta_j}$~\cite{laskey2015bandits}.
After observing $S_{j}$, we update our belief for all grasps $\bg_{\ell} \in \Gamma$ by updating a running count of the fractional successes and failures~\cite{goetschalckx2011continuous}:

\vspace{-2ex}
\begin{align}
	\alpha_{\ell,t} &= \alpha_{\ell,t-1} + k(\mP_{\ell}, \mP_{j}) S_{j} \label{eq:alpha} \\
	\beta_{\ell,t} &= \beta_{\ell,t-1} + k(\mP_{\ell}, \mP_{j}) (1 - S_{j})\label{eq:beta}.
\end{align}

\begin{algorithm}
{\small
    \SetAlgoLined
    {\bf Input:} Object $\mO$, Number of Candidate Grasps $K$, Number of Nearest Neighbors $M$, Dex-Net 1.0 Dataset $\mD$, Feature maps $\psi$ and $\eta$,  Maximum Iterations $T$, Prior beta shape $\alpha_0$, $\beta_0$, Lower Bound Confidence $q$, Quality Metric $S$ \\
    \KwResult{Estimate of the grasp with highest $P_F$, $\hat{\bg}^*$}
    
    \tcp{Generate candidate grasps and priors}
	$\Gamma$ = AntipodalGraspSample($\mO, K$) \;
	$\mA_0 = \varnothing, \mB_0 = \varnothing$\;
	\For{$\bg_k \in \Gamma$}{
		\tcp{Equations~\ref{eq:alpha-prior} and ~\ref{eq:beta-prior}}
		$\alpha_{k,0}, \beta_{k,0} =$ ComputePriors($\mO, \bg_k, \mD, M, \psi$)\; 
		$\mA_0 = \mA_0 \cup \{\alpha_{k,0}\}, \mB_0 = \mB_0 \cup \{\beta_{k,0}\}$\;
	}
	
	\tcp{Run MAB to Evaluate Grasps}
	\For{$t = 1, .., T$}{
		$j = $ ThompsonSample($\mA_{t-1}, \mB_{t-1}$)\;
		$S_{j} = $ SampleQuality($\bg_j, \mO$)\;
		\tcp{Equations~\ref{eq:alpha} and ~\ref{eq:beta}}
		$\mA_{t}, \mB_{t} = $ UpdateBeta($j, S_j, \Gamma$)\; 
		$\bg_{t}^* = $MaxLowerConfidence($q, \mA_{t}, \mB_{t}$)\;
	}
	return $\bg_T^*$\;
    \nonl {\bf Dex-Net 1.0 Algorithm}: Robust Grasp Planning Using Multi-Armed Bandits with Correlated Rewards
}
\end{algorithm}

