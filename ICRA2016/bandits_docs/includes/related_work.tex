\section{Related Work}

Many works on grasp planning focus on finding grasps by maximizing a grasp quality metric, such as the ability to resist external perturbations to the object in wrench space~\cite{ferrari1992, miller2004graspit}.
These metrics have been used to synthesize grasps for known objects using sampling-based optimization in software tools such as GraspIt!~\cite{miller2004graspit} or OpenGRASP~\cite{leon2010opengrasp}.
However, analytic grasp quality metrics have been criticized for relying on perfect knowledge of object shape, pose, material properties, and locations of contact~\cite{cheong2011output, diankov2010automated, weisz2012pose, zheng2005} and for not taking into account the dynamics of the the grasp~\cite{bicchi2000robotic, prattichizzo2008grasping}.
Recent work has also suggested that grasp closure metrics may fail to accurately predict of grasp success on a physical robot~\cite{balasubramanian2012physical, weisz2012pose}.
This has motivated work on transferring known grasps from a database to new objects, evaluating robust versions of analytic quality metrics with respect to uncertainty in the state of the robot and environment, and work on data-driven grasp synthesis.

Many works have approached grasp synthesis for unknown or familiar objects by transferring grasps from a benchmark set of exemplar objects in a large database.
%Ciocarlie et al.~\cite{ciocarlie2009} found that human hand postures lie on a low-dimensional subspace, called eigen-grasps, and exploited this structure to speed up grasp optimization to synthesize grasps at a large scale in GraspIt!.
Li and Pollard~\cite{li2005shape} generated grasps by matching object shapes to human hand postured in a database.
Goldfelder et al.~\cite{goldfeder2009columbia} developed the Columbia grasp database, a database of 1,814 distinct models and over 200,000 form closure grasps generated using the Eigengrasp planner in GraspIt!~\cite{ciocarlie2009}.
The authors later used synthetic partial depth maps of objects in the database to match robot sensor data to precomputed grasps, using the Iterated Closest Point (ICP) algorithm to align the coordinate frames of the depth maps~\cite{goldfeder2009data, goldfeder2011data}.
Several works have also transferred grasps from objects of the same category by warping contacts betwen corresponding points on a shape surface and locally replanning using local rigid alignment and contact interpolation~\cite{hillenbrand2012transferring, stouraitis2015functional} or by interpolating a shape and grasp over a Grasp Moduli Space~\cite{pokorny2013grasp, pokorny2014grasp}.
Detry et al.~\cite{detry2012generalizing} create a low-dimensional representation of object parts and cluster object parts that are grasped similarly to form a shape library of prototypical grasp parts, and show that this representation can be transferred to real sensor data~\cite{detry2013learning}.

Work on evaluating grasp quality metrics under uncertainty, such as the probability of force closure, has considered uncertainty in the state of a robotic gripper~\cite{goldberg1990bayesian, stulp2011learning} and uncertainty in contact locations with an object~\cite{zheng2005}.
Recent work has also studied the effects of uncertainty in object pose and gripper positioning~\cite{brook2011collaborative, hsiao2011bayesian}.
Brook, Ciocarlie, and Hsiao~\cite{brook2011collaborative, hsiao2011bayesian} studied a Bayesian framework to evaluate the probability of grasp success given uncertainty in object identity, gripper positioning, and pose by simulating grasps on deterministic mesh and point cloud models.
Weisz et al.~\cite{weisz2012pose} and Kim et al.~\cite{kim2012physically} independently found that grasps ranked by probability of force closure subject to perturbations of object pose in simulation were empirically more successful on a physical robot than grasps planned using deterministic wrench space metrics. 
Many works have also studied grasping under object shape uncertainty resulting from imprecision of object segmentations in images~\cite{christopoulos2007handling}, part tolerancing in manufacturing~\cite{kehoe2012estimating, kehoe2012toward}, or missing and noisy data from depth sensors such as the Kinect modeled with Gaussian process implicit surfaces~\cite{mahler2015gp, laskey2015bandits}.
Many have also studied caging gripper configurations~\cite{rimon1996caging}, which are a waypoint to form closure grasps for two fingers~\cite{vahedi2008caging, rodriguez2012caging} and may be robust to perturbations in object pose and shape~\cite{diankov2008manipulation, Wan2012_ICRA}.

Another approach for synthesizing grasps on objects is to sample grasps and rank them according to metrics derived from human labels or physical execution~\cite{bohg2014data}.
Saxena et al.~\cite{jiang2011efficient, saxena2008robotic} used a logistic regression classified to predict grasp afordances in images from human annotated training data.
Several other works have examined predicting grasp points using depth edges~\cite{rao2010grasping}, combinations of 2D and 3D edges~\cite{le2010learning}, and global shape descriptors~\cite{bohg2010learning}. 
Lenz et al~\cite{lenz2015deep} used deep learning to detect grasp bounding boxes in color and depth images, which was later extended to real time by Redmon and Angelova~\cite{redmon2014real}.
Many works have also considered predicting grasp success from 3D point clouds.
Herzog et al.~\cite{herzog2012template, herzog2014learning} extract "heightmaps" of local object curvature from human demonstrated grasps, construct a library of heightmap templates, and match new sensor data to templates to select grasps similar to the demonstrations.
Kappler et al.~\cite{kappler2015leveraging} trained a deep neural network to predict human labelled grasps for a Barett hand on a database of synthetic pointclouds of objects.
Recently, several other works have proposed to form a huge database of grasps on synthetic objects from simulation outcomes~\cite{michalikg3db} or physical execution~\cite{tellex}.
In comparison, our work studies the convergence rate for adaptively acquiring samples for evaluating and ranking grasps by their likelihood of success through the use of data-driven grasp correlations based on local and global features of an object surface.

Many works have also considered using data-driven approaches for actively selecting grasps.
Several works have studied active search for successful grasps by minimzing uncertainty about the state of the envirnoment~\cite{hsiao2007grasping, kahnactive, fischinger2015learning}, but without use of an explicit grasp quality metric to guide the search.
Kehoe et al.~\cite{kehoe2012estimating} proposed iterative pruning, an algorithm for evaluating the probability of force closure for a set of candidate grasps while discrading grasps known to have poor quality.
Tellex et al.~\cite{} proposed an initiative to adaptively collect a dataset of grasps and point clouds for one million objects using MAB and reinforcemen learning.
Detry et al.~\cite{detry2011learning} estimated a full continuous density function over grasp poses using kernel density estimation and adaptively acquired samples by pruning unsuccessful grasps.
Recently, Laskey et al.~\cite{laskey2015bandits} showed that Multi-Armed Bandit algorithms can be used to accelerate the identification of grasps with high probability of force closure under uncertainty in shape, pose, and friction in 2D over candidate sets of 1,000 grasps on 88 objects. 
MAB algorithms select the next grasp to sample by trading off gaining information about grasps with few samples and exploiting the success of grasps known to work well.
In robotics, MAB algorithms have also been for speeding up probabilistic roadmap motion planning by adaptively sampling waypoints~\cite{hsu2005hybrid}, searching for the best state machine for a particular task~\cite{matikainen2013multi}, solving mixed observable POMDPs~\cite{Mikko2015POMDP}, and multi-agent navigation~\cite{godoy2015adaptive}.

One shortcoming of the MAB model used by Laskey et al. is that it did not take into account correlations between grasps~\cite{laskey2015bandits}.
In reality, grasp correlations may occur from grasps with similar configurations~\cite{ciocarlie2009, detry2011learning}, objects with similar global structure~\cite{pokorny2013grasp}, or on point cloud surfaces with similar local geometry~\cite{boularias2011learning, herzog2012template, kroemer2010combining, saxena2008robotic}.
Correlated Multi-Armed Bandit (CMAB) models, sometimes also referred to as Bayesian Optimization models~\cite{brochu2010tutorial}, have been used to trading off infromation gathering and exploitation in applicatoins such as ad-serving~\cite{chu2011contextual} and envrionmental monitoring in robotics~\cite{hitz2014fully, marchant2012bayesian}.
Perhaps the most common model of correlations in a CMAB is a linear model~\cite{chu2011contextual}, however this depends on the selection of features are linearly related to a success criteria.
Another common model of correlations is a Gaussian Process (GP)~\cite{rasmussen2006}, which can model nonlinear relationships between options and rewards.
Kroemer et al.~\cite{kroemer2010combining} developed a reinforcement learning approach to grasp selection based on seeding hypothesse via imitation learning and Gaussian process upper-confidence bounds to predict grasp successeses and determine the next grasp to select.
Boularias et al.~\cite{boularias2014efficient} used a Gaussian process Bayesian Optimization model for selecting grasps on cluttered piles of rocks. 
However, GP models are expensive to update with new observations ($O(n^2)$ where $n$ is the number of observations so far)~\cite{rasmussen2006}, which limited the scale of experiments in both simulation and the physical world that the authors could perform.
To make the model more tractable, Boularias et al. later extended their work to use an heuristic upper confidence bound-based reinforcement learning~\cite{boularias2015learning}.
Recently, Goetschalckx et al.~\cite{goetschalckx2011continuous} developed the Continuous Correlated Beta Process (CCBP), a nonlinear model of 0-1 reward probabilities.
CCBPs are inexpensive to update compared to GPs, requiring $O(n)$ time in the worst case and a much smaller factor when efficient nearest neighbor queries can be performed~\cite{goetschalckx2011continuous}.
Montesano and Lopes~\cite{montesano2012active} used CCBPs (although the authors did not refer to them as CCBPs) to actively acquire grasp executions, measuring correlations from the responses to a bank of 151 image filters.
In this work we also utilize CCBPs to model correaltions between grasps, and study their performance on grasping simulations over thousands of objects.









