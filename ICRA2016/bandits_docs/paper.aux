\relax 
\citation{kehoe2015survey}
\citation{hannun2014deepspeech,krizhevsky2012imagenet}
\citation{goldfeder2011data,lenz2015deep,kappler2015leveraging}
\citation{laskey2015bandits}
\citation{kehoe2012toward,weisz2012pose}
\citation{laskey2015bandits}
\citation{kehoe2012toward,weisz2012pose}
\citation{goetschalckx2011continuous,montesano2012active}
\citation{su2015multi}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{sec:introduction}{{I}{1}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Average normalized grasp quality versus iteration for 25 trials for the Dex-Net1.0 algorithm with 1,000 and 10,000 prior 3D objects from Dex-Net (bottom) and illustrations of five nearest neighbors in Dex-Net (top) for a spray bottle. We measure quality by the probability of force closure of the best grasp predicted by the algorithm on each iteration and compare with Thompson sampling without priors\nobreakspace  {}\cite  {laskey2015bandits} and uniform allocation\nobreakspace  {}\cite  {kehoe2012toward, weisz2012pose}. (Top) The spray bottle has no similar neighbors with 1,000 objects, but two other spray bottles are found by the MV-CNN in the 10,000 object set. (Bottom) As a result, the Dex-Net 1.0 algorithm quickly converges to the optimal grasp with 10,000 prior objects.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:avg-reward-spray}{{1}{1}}
\citation{pokorny2013c}
\citation{balasubramanian2012physical,kappler2015leveraging}
\citation{bohg2014data}
\citation{stouraitis2015functional}
\citation{pokorny2013grasp}
\citation{goldfeder2009columbia,goldfeder2011data}
\citation{weisz2012pose}
\citation{kim2012physically}
\citation{weisz2012pose}
\citation{kim2012physically}
\citation{brook2011collaborative}
\citation{kehoe2013cloud}
\citation{bohg2014data}
\citation{lenz2015deep}
\citation{detry2013learning,herzog2014learning,zhang2011graspable}
\citation{herzog2014learning,lenz2015deep}
\citation{herzog2014learning}
\citation{kappler2015leveraging}
\citation{detry2011learning,kroemer2010combining,salganicoff1996active}
\citation{montesano2012active}
\citation{goetschalckx2011continuous}
\citation{pinto2016supersizing}
\citation{oberlin2015autonomously}
\citation{laskey2015bandits}
\citation{bronstein2011shape}
\citation{maturana2015voxnet,wu20153d}
\citation{chen2003visual,goldfeder2011data}
\citation{su2015multi}
\citation{aubry2015understanding}
\citation{mahler2015gp}
\citation{zheng2005}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}}
\newlabel{sec:related}{{II}{2}}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {III}Definitions and Problem Statement}{2}}
\newlabel{sec:problem}{{III}{2}}
\citation{kim2012physically,laskey2015bandits,mahler2015gp,weisz2012pose}
\citation{laskey2015bandits,srinivas10gaussian}
\citation{kehoe2012toward,weisz2012pose}
\citation{laskey2015bandits}
\citation{laskey2015bandits}
\citation{hoffman2013exploiting,pandey2007multi}
\citation{mahler2015gp}
\citation{kim2012physically,weisz2012pose}
\citation{zheng2005}
\citation{weisz2012pose}
\citation{barfoot2014associating}
\citation{pokorny2013c}
\citation{li2015comparison}
\citation{wu20153d}
\citation{wohlkinger20123dnet}
\citation{kasper2012kit}
\citation{singh2014bigbird}
\citation{calli2015benchmarking}
\citation{sdfgen}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of grasp parameterization and contact model. (Left) We parameterize parallel-jaw grasps by the centroid of the jaws $\mathbf  {x}\in \mathbb  {R}^3$ and approach direction, or direction along which the jaws close, $\mathbf  {v}\in \mathbb  {S}^2$. The parameters $\mathbf  {x}$ and $\mathbf  {v}$ are specified with respect to a coordinate frame at the object center of mass $\mathbf  {z}$ and oriented along the principal directions of the object. (Right) The jaws are closed until contacting the object surface at locations $\mathbf  {c}_1, \mathbf  {c}_2 \in \mathbb  {R}^3$, at which the surface has normals $\mathbf  {n}_1, \mathbf  {n}_2 \in \mathbb  {S}^2$. The contacts are used to compute the moment arms $\rho _i = \mathbf  {c}_i - \mathbf  {z}$. \relax }}{3}}
\newlabel{fig:grasp-model}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Grasp and Object Parameterization}{3}}
\newlabel{sec:grasp-param}{{III-A}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Objective}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Quality Metric}{3}}
\newlabel{sec:quality}{{III-C}{3}}
\@LN@col{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}Sources of Uncertainty}{3}}
\newlabel{sec:uncertainty}{{III-D}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-E}Contact Model}{3}}
\newlabel{sec:contact}{{III-E}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Dexterity Network}{3}}
\newlabel{sec:dexnet}{{IV}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Data}{3}}
\citation{smith1999computing}
\citation{mahler2015gp}
\citation{mahler2015gp}
\citation{kehoe2012toward,weisz2012pose}
\citation{herzog2014learning,kappler2015leveraging}
\citation{salti2014shot}
\citation{pokorny2013c}
\citation{su2015multi}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2012imagenet}
\citation{jia2014caffe}
\citation{li2015comparison}
\citation{li2015comparison}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2012imagenet}
\citation{laskey2015bandits,srinivas10gaussian}
\citation{hoffman2013exploiting,pandey2007multi}
\citation{laskey2015bandits,oberlin2015autonomously}
\citation{zheng2005}
\citation{kroemer2010combining,montesano2012active}
\citation{kroemer2010combining,oberlin2015autonomously}
\citation{laskey2015bandits}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Illustration of three local surface depthmaps extracted on a teapot. Each depthmap is ``rendered" along the grasp axis $\mathbf  {v}_i$ at contact $\mathbf  {c}_i$ and oriented by the directions of maximum variation in the depthmap. We use gradients of the depthmaps for similiarity between grasps in Dex-Net.\relax }}{4}}
\newlabel{fig:local-feature-model}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Grasp Sampling}{4}}
\newlabel{sec:grasp-sampling}{{IV-B}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Grasp Differential Depthmap Features}{4}}
\newlabel{sec:grasp-similarity}{{IV-C}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Deep Learning for Object Similarity}{4}}
\newlabel{sec:object-similarity}{{V}{4}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Illustration of our Multi-View Convolutional Neural Network (MV-CNN) deep learning method for embedding 3D object models in a Euclidean vector space to compute global shape similarity. We pass a set of 50 virtually rendered camera viewpoints discretized around a sphere through a deep Convolutional Neural Network (CNN) with the AlexNet\nobreakspace  {}\cite  {krizhevsky2012imagenet} architecture. Finally, we take the maximum fc7 response across each of the 50 views for each dimension and run PCA to reduce dimensionality.\relax }}{4}}
\newlabel{fig:global-feature-model}{{4}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Correlated Multi-Armed Bandit Algorithm}{4}}
\newlabel{sec:algorithm}{{VI}{4}}
\citation{goetschalckx2011continuous,montesano2012active}
\citation{goetschalckx2011continuous}
\citation{goetschalckx2011continuous}
\citation{laskey2015bandits}
\citation{laskey2015bandits}
\citation{goetschalckx2011continuous}
\citation{laskey2015bandits}
\citation{laskey2015bandits}
\citation{kehoe2012toward,kim2012physically,weisz2012pose}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-A}Model of Correlated Rewards}{5}}
\newlabel{sec:belief}{{VI-A}{5}}
\@LN@col{2}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-B}Predicting Grasp Quality Using Prior Data}{5}}
\newlabel{sec:ccbps}{{VI-B}{5}}
\newlabel{eq:obj}{{VI.1}{5}}
\newlabel{eq:alpha-prior}{{VI.2}{5}}
\newlabel{eq:beta-prior}{{VI.3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-C}Grasp Selection Policy}{5}}
\newlabel{eq:alpha}{{VI.4}{5}}
\newlabel{eq:beta}{{VI.5}{5}}
\citation{goetschalckx2011continuous}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Experiments}{6}}
\newlabel{sec:experiments}{{VII}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VII-A}Scaling of Average Convergence Rate}{6}}
\newlabel{sec:conv-rate}{{VII-A}{6}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Average normalized grasp quality versus iteration over 45 test objects and 25 trials per object for the Dex-Net1.0 algorithm with 1,000 and 10,000 prior 3D objects from Dex-Net. We measure quality by the $P_F$ for the best grasp predicted by the algorithm on each iteration and compare with Thompson sampling without priors and uniform allocation. The algorithm converges faster with 10,000 models, never dropping below approximately 90\% of the grasp with highest $P_F$ from a set of 250 candidate grasps.\relax }}{6}}
\newlabel{fig:avg-reward}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VII-B}Sensitivity to Object Shape}{6}}
\newlabel{sec:shape-sens}{{VII-B}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VII-C}Sensitivity to Similarity and Uncertainty}{6}}
\newlabel{sec:band-sens}{{VII-C}{6}}
\citation{krizhevsky2012imagenet}
\bibstyle{IEEEtranS}
\bibdata{bibliography}
\bibcite{aubry2015understanding}{1}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Failure object for the Dex-Net 1.0 algorithm. (Top) The drill, which is relatively rare in the dataset, has no geometrically similar neighbors even with 10,000 objects. (Bottom) Plotted is the average normalized grasp quality versus iteration over 25 trials for the Dex-Net 1.0 algorithm with 1,000 and 10,000 prior 3D objects. The lack of similar objects leads to no significant performance increase over Thompson sampling without priors. \relax }}{7}}
\newlabel{fig:avg-reward-drill}{{6}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Illustration of the grasps predicted to have the highest $P_F$ after only 100 iterations by Thompson sampling without priors and the Dex-Net 1.0 algorithm with 1,000 and 10,000 prior objects. Thompson sampling without priors chooses a grasp near the edge of the object, while the Dex-Net algorithm selects grasps closer to the object center-of-mass.\relax }}{7}}
\newlabel{fig:spray-grasps}{{7}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Discussion and Future Work}{7}}
\newlabel{sec:conclusion}{{VIII}{7}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Sensitivity to similiarity kernel (top) and pose and friction uncertainty (bottom) for the normalized grasp quality versus iteration averaged over 25 trials per object for the Dex-Net algorithm with 1,000 and 10,000 prior 3D objects. (Top-left) Using a higher inverse bandwidth causes the algorithm to measure false similarities between grasps, leading to performance on par with uniform allocation. (Top-right) A lower inverse bandwith decreases the convergence rate, but on average the Dex-Net algorithm still selects a grasp within approximately 85\% of the grasp with highest $P_F$ for all iterations. (Bottom-left) Lower uncertainty increases the quality for all methods, (bottom-right) higher uncertainty decreases the quality for all methods, and the Dex-Net algorithm with 10,000 prior objects still converges approximately 2$\times $ faster than Thompson sampling without priors. \relax }}{7}}
\newlabel{fig:bnu-sens}{{8}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Acknowledgments}{7}}
\bibcite{balasubramanian2012physical}{2}
\bibcite{barfoot2014associating}{3}
\bibcite{sdfgen}{4}
\bibcite{bohg2014data}{5}
\bibcite{bronstein2011shape}{6}
\bibcite{brook2011collaborative}{7}
\bibcite{calli2015benchmarking}{8}
\bibcite{chen2003visual}{9}
\bibcite{detry2013learning}{10}
\bibcite{detry2011learning}{11}
\bibcite{goetschalckx2011continuous}{12}
\bibcite{goldfeder2011data}{13}
\bibcite{goldfeder2009columbia}{14}
\bibcite{hannun2014deepspeech}{15}
\bibcite{herzog2014learning}{16}
\bibcite{hoffman2013exploiting}{17}
\bibcite{jia2014caffe}{18}
\bibcite{kappler2015leveraging}{19}
\bibcite{kasper2012kit}{20}
\bibcite{kehoe2012toward}{21}
\bibcite{kehoe2013cloud}{22}
\bibcite{kehoe2015survey}{23}
\bibcite{kim2012physically}{24}
\bibcite{krizhevsky2012imagenet}{25}
\bibcite{kroemer2010combining}{26}
\bibcite{laskey2015bandits}{27}
\bibcite{lenz2015deep}{28}
\bibcite{li2015comparison}{29}
\bibcite{mahler2015gp}{30}
\bibcite{maturana2015voxnet}{31}
\bibcite{montesano2012active}{32}
\bibcite{oberlin2015autonomously}{33}
\bibcite{pandey2007multi}{34}
\bibcite{pinto2016supersizing}{35}
\bibcite{pokorny2013grasp}{36}
\bibcite{pokorny2013c}{37}
\bibcite{salganicoff1996active}{38}
\bibcite{salti2014shot}{39}
\bibcite{singh2014bigbird}{40}
\bibcite{smith1999computing}{41}
\bibcite{srinivas10gaussian}{42}
\bibcite{stouraitis2015functional}{43}
\bibcite{su2015multi}{44}
\bibcite{weisz2012pose}{45}
\bibcite{wohlkinger20123dnet}{46}
\bibcite{wu20153d}{47}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{References}{8}}
\@LN@col{2}
\bibcite{zhang2011graspable}{48}
\bibcite{zheng2005}{49}
\@LN@col{1}
\@LN@col{2}
